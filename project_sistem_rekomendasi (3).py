# -*- coding: utf-8 -*-
"""Project sistem rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Dp0Iv1xvleaRgwuH8eYbrmt7eIK5bbpx

# Sistem Rekomendasi Film (Content-Based Filtering)

Proyek ini bertujuan untuk membangun sistem rekomendasi film berbasis konten (content-based), yaitu merekomendasikan film berdasarkan kesamaan konten dengan film yang dipilih user, menggunakan teknik NLP dan similarity.

# Data Loading
"""

import pandas as pd
import numpy as np
import ast
import zipfile
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel,cosine_similarity
from sklearn.preprocessing import MinMaxScaler
from scipy.sparse.linalg import svds

zip_path = 'archive (4).zip'  # nama file zip kamu
extract_folder = 'tmdb_dataset'

if not os.path.exists(extract_folder):
    os.makedirs(extract_folder)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

print(f"File berhasil diekstrak ke folder: {extract_folder}")

"""**Hasil Ekstraksi Dataset:**

File zip berhasil diekstrak ke dalam folder `tmdb_dataset`. Langkah selanjutnya adalah memeriksa isi folder tersebut untuk memastikan file CSV yang dibutuhkan tersedia.
"""

# Cek isi folder hasil ekstraksi
print("Isi folder tmdb_dataset:")
print(os.listdir('tmdb_dataset'))

"""**Isi Folder Dataset:**

Folder `tmdb_dataset` berisi dua file CSV: `tmdb_5000_movies.csv` dan `tmdb_5000_credits.csv`. Kedua file ini akan digunakan untuk membangun sistem rekomendasi.
"""

# Load kedua dataset
movies_df = pd.read_csv('tmdb_dataset/tmdb_5000_movies.csv')
credits_df = pd.read_csv('tmdb_dataset/tmdb_5000_credits.csv')

print("✅ Dataset berhasil dimuat!")

"""**Dataset Berhasil Dimuat:**

Kedua dataset (`movies_df` dan `credits_df`) berhasil dimuat ke dalam pandas DataFrame. Langkah selanjutnya adalah memahami struktur dan konten dari masing-masing DataFrame.

# Data Understanding

Pada tahap ini kita akan melakukan eksplorasi awal terhadap struktur dan konten dataset:

- Melihat informasi struktur dataset (jumlah baris, kolom, tipe data, missing values).
- Menyambungkan data `credits_df` ke `movies_df` berdasarkan kolom id.
- Menampilkan beberapa data teratas dari DataFrame gabungan.

Melihat informasi umum dari `movies_df` untuk memahami kolom-kolom yang tersedia, tipe datanya, dan keberadaan missing values.
"""

# 4. Tampilkan info umum
print("\nInformasi Dataset Movies:")
print(movies_df.info())

"""**Informasi Dataset Movies:**

Dataset `movies_df` memiliki 4803 baris dan 20 kolom. Terdapat beberapa kolom dengan tipe data objek (string) yang kemungkinan berisi data terstruktur seperti JSON string (misalnya 'genres', 'keywords', 'production_companies', 'cast', 'crew'). Beberapa kolom juga memiliki missing values, terutama 'homepage', 'tagline', 'overview', 'release_date', dan 'runtime'.

Melihat informasi umum dari `credits_df` untuk memahami kolom-kolom yang tersedia dan tipe datanya.
"""

print("\nInformasi Dataset Credits:")
print(credits_df.info())

"""**Informasi Dataset Credits:**

Dataset `credits_df` memiliki 4803 baris dan 4 kolom. Kolom 'cast' dan 'crew' bertipe objek dan kemungkinan berisi data terstruktur dalam format JSON string. Dataset ini tidak memiliki missing values. Kolom 'movie_id' akan digunakan untuk menggabungkan dengan `movies_df`.

Menampilkan beberapa baris pertama dari `movies_df` untuk mendapatkan gambaran awal tentang format data.
"""

# 5. Tampilkan contoh data
print("\nContoh Data Movies:")
print(movies_df.head(2))

"""**Contoh Data Movies:**

Contoh data menunjukkan bahwa kolom seperti 'genres', 'keywords', 'production_companies', 'production_countries', 'spoken_languages', 'cast', dan 'crew' memang berisi string yang terlihat seperti representasi list atau dictionary JSON. Kolom 'overview' dan 'tagline' berisi deskripsi tekstual.

Menampilkan beberapa baris pertama dari `credits_df` untuk mendapatkan gambaran awal tentang format data.
"""

print("\nContoh Data Credits:")
print(credits_df.head(2))

"""**Contoh Data Credits:**

Contoh data menunjukkan bahwa `credits_df` berisi informasi 'movie_id', 'title', 'cast', dan 'crew'. Kolom 'cast' dan 'crew' berisi string JSON yang detail.

# Univariate Exploratory Data Analysis (EDA)

Melakukan analisis deskriptif pada setiap variabel untuk memahami distribusi dan karakteristik data.

Mengatur opsi tampilan pandas agar semua kolom DataFrame ditampilkan saat menggunakan `.head()` atau `.info()`.
"""

# Tampilkan semua kolom dataframe
pd.set_option('display.max_columns', None)

"""Mengganti nama kolom 'movie_id' pada `credits_df` menjadi 'id' agar sesuai dengan nama kolom id pada `movies_df`, sehingga kedua DataFrame dapat digabungkan dengan mudah."""

# Rename kolom supaya bisa merge
credits_df.rename(columns={'movie_id': 'id'}, inplace=True)

"""Melakukan pengecekan jumlah nilai yang hilang (missing value) pada setiap kolom di `movies_df` sebelum digabungkan."""

print("Jumlah missing value per kolom:\n", movies_df.isnull().sum())

"""**Insight Missing Value:**

Kolom 'homepage' memiliki jumlah missing value terbanyak (3091). Kolom lain seperti 'tagline' (844), 'overview' (3), 'runtime' (2), dan 'release_date' (1) juga memiliki missing values, namun dalam jumlah yang jauh lebih sedikit. Kolom 'homepage' tidak akan digunakan dalam model content-based, sedangkan missing value pada kolom lain akan ditangani pada tahap preprocessing.

Menggabungkan kedua DataFrame (`movies_df` dan `credits_df`) menjadi satu DataFrame tunggal berdasarkan kolom 'id'. Setelah digabung, menampilkan beberapa baris pertama untuk memverifikasi hasilnya.
"""

# Merge kedua dataset
movies_df = movies_df.merge(credits_df, on='id')

# Tampilkan beberapa baris pertama
movies_df.head()

"""**Hasil Merge Dataset:**

Kedua dataset berhasil digabungkan menjadi satu DataFrame `movies_df`. DataFrame gabungan ini sekarang memiliki kolom dari kedua dataset, termasuk 'cast' dan 'crew'. Terlihat ada dua kolom 'title' (`title_x` dan `title_y`) karena keduanya memiliki kolom 'title', ini akan ditangani di tahap selanjutnya.

Visualisasi sebaran nilai `vote_average` pada film untuk mengetahui pola distribusinya. Ini memberikan gambaran tentang bagaimana rating film tersebar dalam dataset.
"""

#Visualisasi Distribusi Rating Film
plt.figure(figsize=(8,5))
sns.histplot(movies_df['vote_average'], bins=20, kde=True, color='skyblue')
plt.title("Distribusi Skor Vote Average Film", fontsize=14)
plt.xlabel("Vote Average")
plt.ylabel("Jumlah Film")
plt.grid(True, linestyle='--', alpha=0.4)
plt.show()

"""**Insight Distribusi Vote Average:**

Distribusi skor `vote_average` cenderung terpusat antara 5 hingga 8. Ini menunjukkan bahwa sebagian besar film dalam dataset memiliki rating dalam kisaran ini. Ada juga film dengan rating sangat rendah atau sangat tinggi, namun jumlahnya lebih sedikit.

Visualisasi distribusi genre film untuk mengetahui genre apa yang paling banyak muncul dalam dataset.
"""

#Visualisasi Distribusi Genre
# Fungsi untuk parsing JSON-like text
def extract_genres(obj):
    try:
        return [d['name'] for d in ast.literal_eval(obj)]
    except:
        return []

movies_df['genres_list'] = movies_df['genres'].apply(extract_genres)

# Hitung semua genre
from collections import Counter
all_genres = sum(movies_df['genres_list'], [])
genre_count = Counter(all_genres)

# Visualisasi
plt.figure(figsize=(12,6))
sns.barplot(x=list(genre_count.keys()), y=list(genre_count.values()), palette='viridis')
plt.xticks(rotation=45)
plt.title("Distribusi Genre Film", fontsize=14)
plt.ylabel("Jumlah Film")
plt.grid(True, linestyle='--', alpha=0.3)
plt.tight_layout()
plt.show()

"""**Insight Distribusi Genre:**

Tiga genre paling umum dalam dataset adalah Drama, Comedy, dan Thriller. Ini mengindikasikan bahwa dataset ini memiliki representasi yang kuat untuk genre-genre tersebut, yang akan mempengaruhi rekomendasi berbasis konten.

Visualisasi distribusi runtime (durasi) film untuk mengetahui sebaran durasi film dalam dataset.
"""

#Distribusi Runtime Film
plt.figure(figsize=(8, 5))
sns.histplot(movies_df['runtime'].dropna(), bins=30, color='orange', kde=True)
plt.title('Distribusi Durasi Film (Runtime)', fontsize=14)
plt.xlabel('Durasi (menit)')
plt.ylabel('Jumlah Film')
plt.grid(True, linestyle='--', alpha=0.3)
plt.show()

"""**Insight Distribusi Runtime:**

Durasi film rata-rata dalam dataset adalah sekitar 100 menit. Distribusi ini menunjukkan sebagian besar film memiliki durasi standar film layar lebar, namun ada juga beberapa film dengan durasi yang sangat pendek atau sangat panjang.

Menampilkan 10 film teratas berdasarkan skor popularitas untuk mengetahui film mana yang paling populer dalam dataset ini.
"""

#10 Film Terpopuler Berdasarkan Popularitas
popular_movies = movies_df[['title_x', 'popularity']].sort_values(by='popularity', ascending=False).head(10)

plt.figure(figsize=(10,6))
sns.barplot(data=popular_movies, x='popularity', y='title_x', palette='mako')
plt.title("10 Film dengan Skor Popularitas Tertinggi")
plt.xlabel("Skor Popularitas")
plt.ylabel("Judul Film")
plt.tight_layout()
plt.show()

"""**Insight Film Terpopuler:**

Berdasarkan skor popularitas, film-film seperti The Dark Knight, The Avengers, dan Inception termasuk yang paling populer dalam dataset ini. Popularitas ini didasarkan pada metrik internal TMDB.

Visualisasi korelasi antara popularitas dan vote average untuk melihat apakah ada hubungan antara seberapa populer sebuah film dengan rata-rata rating yang diterimanya.
"""

#Korelasi: Popularitas vs Vote Average
plt.figure(figsize=(7, 5))
sns.scatterplot(data=movies_df, x='popularity', y='vote_average', alpha=0.6)
plt.title("Korelasi antara Popularitas dan Skor Vote")
plt.xlabel("Popularitas")
plt.ylabel("Vote Average")
plt.grid(True, linestyle='--', alpha=0.3)
plt.show()

"""**Insight Korelasi Popularitas vs Vote Average:**

Scatter plot menunjukkan adanya korelasi positif antara popularitas dan vote average, meskipun tidak sempurna. Film dengan popularitas sangat tinggi cenderung memiliki vote average yang baik, namun ada juga film dengan popularitas rendah yang memiliki vote average tinggi, dan sebaliknya.

Menganalisis jumlah film yang dirilis setiap tahun untuk melihat tren produksi film dari waktu ke waktu.
"""

#Jumlah Film Tiap Tahun

# Pastikan kolom release_date berupa datetime
movies_df['release_date'] = pd.to_datetime(movies_df['release_date'], errors='coerce')
movies_df['release_year'] = movies_df['release_date'].dt.year

# Hitung jumlah film per tahun
film_per_year = movies_df['release_year'].value_counts().sort_index()

plt.figure(figsize=(12,6))
sns.lineplot(x=film_per_year.index, y=film_per_year.values)
plt.title("Jumlah Film Dirilis per Tahun", fontsize=14)
plt.xlabel("Tahun Rilis")
plt.ylabel("Jumlah Film")
plt.grid(True, linestyle='--', alpha=0.4)
plt.tight_layout()
plt.show()

"""**Insight Jumlah Film per Tahun:**

Grafik menunjukkan tren peningkatan jumlah film yang dirilis dari tahun ke tahun, dengan puncak produksi terjadi di tahun-tahun yang lebih baru dalam dataset ini. Ini mengindikasikan dataset mencakup periode waktu dengan aktivitas produksi film yang bervariasi.

# Data Preparation
Tahap ini fokus pada persiapan data untuk pemodelan content-based filtering. Langkah-langkah yang dilakukan meliputi:

- Menghapus kolom yang tidak relevan ('homepage').
- Mengisi missing value pada kolom tekstual ('overview', 'tagline') dengan string kosong untuk menghindari error saat penggabungan teks.
- Menghapus baris dengan missing value pada 'release_date' karena jumlahnya sangat sedikit dan sulit diimputasi tanpa informasi tambahan.
- Mengisi missing value pada 'runtime' dengan nilai median runtime untuk mempertahankan jumlah data sebanyak mungkin.
- Mengekstrak informasi relevan (nama genre, kata kunci, pemeran utama, sutradara) dari kolom yang formatnya mirip JSON string.
- Membersihkan data yang diekstrak (menghilangkan spasi dan mengubah ke huruf kecil) agar konsisten dan siap untuk vectorization.
- Menggabungkan semua fitur tekstual dan kategorikal yang relevan ('genres', 'keywords', 'cast', 'crew', 'overview') menjadi satu kolom baru bernama 'tags'. Kolom 'tags' ini akan menjadi input utama untuk membangun model content-based.
- Membuat DataFrame baru (`movie_data`) yang hanya berisi kolom 'id', 'title', dan 'tags'.

Menghapus kolom 'homepage' karena memiliki banyak missing values dan tidak relevan untuk model content-based filtering. Mengisi missing value pada kolom 'overview' dan 'tagline' dengan string kosong. Menghapus baris dengan missing value pada 'release_date'. Mengisi missing value pada 'runtime' dengan median. Terakhir, mencetak jumlah missing value per kolom untuk memverifikasi hasil pembersihan.

## Data Cleaning
"""

# 1. Drop kolom homepage karena tidak relevan
movies_df.drop(columns=['homepage'], inplace=True)

# 2. Isi missing value overview dan tagline dengan string kosong
movies_df['overview'] = movies_df['overview'].fillna('')
movies_df['tagline'] = movies_df['tagline'].fillna('')

# 3. Drop baris dengan release_date kosong (jumlahnya sangat kecil)
movies_df = movies_df.dropna(subset=['release_date'])

# 4. Isi runtime yang kosong dengan median runtime
runtime_median = movies_df['runtime'].median()
movies_df['runtime'] = movies_df['runtime'].fillna(runtime_median)

# Cek ulang apakah masih ada missing value
print("✅ Missing value setelah dibersihkan:\n")
print(movies_df.isnull().sum())

"""**Hasil Penanganan Missing Value:**

Missing values pada kolom 'homepage', 'overview', 'tagline', 'release_date', dan 'runtime' telah ditangani sesuai strategi yang ditentukan. DataFrame sekarang bersih dari missing values pada kolom-kolom yang akan digunakan.

## Data Transformation

Mendefinisikan fungsi-fungsi bantu untuk mengekstrak informasi dari kolom yang berisi JSON string ('genres', 'keywords', 'cast', 'crew'). Fungsi `parse_names` mengekstrak nama dari list dictionary, `get_top_cast` mengambil 3 nama pemeran utama, dan `get_director` mengambil nama sutradara.
"""

#Proses Ekstraksi dan Pembersihan Data
# Parsing data bertipe list/dictionary (JSON string)
# Fungsi bantu
def parse_names(text):
    try:
        return [i['name'] for i in ast.literal_eval(text)]
    except:
        return []

def get_top_cast(text):
    try:
        return [i['name'] for i in ast.literal_eval(text)[:3]]  # ambil 3 aktor
    except:
        return []

def get_director(text):
    try:
        for i in ast.literal_eval(text):
            if i.get('job') == 'Director':
                return i['name']
        return ''
    except:
        return ''

"""Menerapkan fungsi-fungsi parsing ke kolom 'genres', 'keywords', 'cast', dan 'crew' untuk mengubah string JSON menjadi list Python yang berisi nama-nama yang relevan."""

movies_df['genres'] = movies_df['genres'].apply(parse_names)
movies_df['keywords'] = movies_df['keywords'].apply(parse_names)
movies_df['cast'] = movies_df['cast'].apply(get_top_cast)
movies_df['crew'] = movies_df['crew'].apply(get_director)

"""Mendefinisikan fungsi `clean_list` untuk membersihkan elemen dalam list atau string dengan menghilangkan spasi dan mengubah teks menjadi huruf kecil. Ini penting untuk standardisasi teks sebelum vectorization. Kemudian, menerapkan fungsi ini ke kolom 'genres', 'keywords', 'cast', dan 'crew'."""

def clean_list(x):
    if isinstance(x, list):
        return [i.replace(" ", "").lower() for i in x]
    elif isinstance(x, str):
        return x.replace(" ", "").lower()
    return ''

movies_df['genres'] = movies_df['genres'].apply(clean_list)
movies_df['keywords'] = movies_df['keywords'].apply(clean_list)
movies_df['cast'] = movies_df['cast'].apply(clean_list)
movies_df['crew'] = movies_df['crew'].apply(clean_list)

"""Memastikan kolom 'overview' tidak kosong (meskipun sudah diisi string kosong di awal) dan menggabungkan semua fitur tekstual dan kategorikal yang relevan ('genres', 'keywords', 'cast', 'crew', 'overview') menjadi satu string panjang di kolom baru 'tags'. Kolom 'tags' ini akan merepresentasikan konten dari setiap film."""

# Pastikan overview tidak kosong
movies_df['overview'] = movies_df['overview'].fillna('')

# Gabungkan fitur jadi satu string
movies_df['tags'] = movies_df.apply(
    lambda x: ' '.join(x['genres']) + ' ' +
              ' '.join(x['keywords']) + ' ' +
              ' '.join(x['cast']) + ' ' +
              x['crew'] + ' ' +
              x['overview'],
    axis=1
)

"""Membuat DataFrame baru `movie_data` yang hanya berisi kolom 'id', 'title' (menggunakan `title_x` dan mengganti namanya), dan 'tags'. Menampilkan beberapa baris pertama dari `movie_data` untuk memverifikasi hasilnya. DataFrame ini akan menjadi input untuk tahap vectorization."""

movie_data = movies_df[['id', 'title_x', 'tags']].copy()
movie_data.rename(columns={'title_x': 'title'}, inplace=True)
movie_data.head(3)

"""**DataFrame movie_data:**

DataFrame `movie_data` kini berisi kolom 'id', 'title', dan 'tags' yang merupakan gabungan informasi dari berbagai fitur film. Kolom 'tags' telah dibersihkan dan siap untuk diubah menjadi representasi numerik.

## Feature Encoding:
"""

# Buat vectorizer dan batasi jumlah fitur (bisa disesuaikan)
tfidf = TfidfVectorizer(max_features=5000, stop_words='english')

# Fit dan transform kolom 'tags' menjadi vektor numerik
tfidf_matrix = tfidf.fit_transform(movie_data['tags'])

# Cek bentuk matriks TF-IDF
print("✅ TF-IDF Matrix Shape:", tfidf_matrix.shape)

"""**Hasil TF-IDF Vectorization:**

Kolom 'tags' berhasil diubah menjadi matriks TF-IDF dengan bentuk (4802, 5000). Ini berarti terdapat 4802 film (dokumen) yang direpresentasikan oleh 5000 fitur (kata) yang paling signifikan setelah menghapus stop words dan membatasi jumlah fitur.

# Model Development - Content-Based Filtering
Dengan matriks kesamaan yang telah dihitung, kita bisa membangun fungsi rekomendasi film berbasis konten:

- Membuat fungsi `recommend()` yang menerima judul film (`title`) sebagai input dan mengembalikan daftar film yang direkomendasikan.
- Fungsi ini akan mencari indeks film input dalam DataFrame `movie_data`.
- Mengambil baris kesamaan yang sesuai dari `similarity_matrix` untuk film tersebut.
- Mengurutkan film lain berdasarkan skor kesamaan secara menurun.
- Mengabaikan film itu sendiri (skor kesamaannya akan 1.0) dan mengambil sejumlah film teratas (*top_n*).
- Menampilkan judul film rekomendasi beserta skor kesamaannya.

Mendefinisikan fungsi `recommend` yang mengambil judul film dan jumlah rekomendasi yang diinginkan (`top_n`). Fungsi ini mencari film berdasarkan judul (tidak case-sensitive), mendapatkan indeksnya, menghitung kesamaan dengan semua film lain, mengurutkannya, dan mengembalikan judul film-film teratas yang paling mirip.

Menghitung matriks kesamaan (similarity matrix) antar semua film berdasarkan matriks TF-IDF menggunakan `cosine_similarity`. Cosine similarity mengukur sudut antara dua vektor non-nol, menunjukkan seberapa mirip arah vektor tersebut. Matriks ini akan memiliki ukuran NxN, di mana N adalah jumlah film, dan setiap elemen (i, j) menunjukkan kesamaan antara film i dan film j. Setelah perhitungan, mencetak bentuk similarity matrix.
"""

# Menghitung cosine similarity antar semua film
similarity = cosine_similarity(tfidf_matrix)

# Cek bentuk similarity matrix
print("✅ Cosine Similarity Matrix Shape:", similarity.shape)

def recommend(title, top_n=5):
    title = title.lower()
    if title not in movie_data['title'].str.lower().values:
        return f"🎬 Film '{title}' tidak ditemukan dalam dataset."

    index = movie_data[movie_data['title'].str.lower() == title].index[0]
    distances = list(enumerate(similarity[index]))
    sorted_distances = sorted(distances, key=lambda x: x[1], reverse=True)[1:top_n+1]

    print(f"\n📽️ Rekomendasi film mirip dengan '{movie_data.iloc[index].title}':")
    for i, (idx, score) in enumerate(sorted_distances, 1):
        print(f"{i}. {movie_data.iloc[idx].title} (Similarity: {score:.2f})")

"""Mendefinisikan fungsi `evaluate_recommendation` untuk memberikan evaluasi sederhana terhadap hasil rekomendasi. Fungsi ini mirip dengan `recommend` tetapi juga menghitung rata-rata skor similarity dari film-film yang direkomendasikan dan memberikan kesimpulan relevansi berdasarkan rata-rata skor tersebut."""

def evaluate_recommendation(title, top_n=5):
    title_lower = title.lower()
    if title_lower not in movie_data['title'].str.lower().values:
        print(f"Film '{title}' tidak ditemukan dalam dataset.")
        return

    index = movie_data[movie_data['title'].str.lower() == title_lower].index[0]
    distances = list(enumerate(similarity[index]))
    sorted_distances = sorted(distances, key=lambda x: x[1], reverse=True)[1:top_n+1]

    recommended_titles = [movie_data.iloc[idx].title for idx, score in sorted_distances]
    similarity_scores = [score for idx, score in sorted_distances]

    print(f"Rekomendasi untuk film '{title}':")
    for i, (rec_title, score) in enumerate(zip(recommended_titles, similarity_scores), 1):
        print(f"{i}. {rec_title} (Similarity: {score:.4f})")

    avg_similarity = np.mean(similarity_scores)
    print(f"\nRata-rata skor similarity dari rekomendasi: {avg_similarity:.4f}")

    # Kesimpulan sederhana
    if avg_similarity > 0.5:
        print("Evaluasi: Rekomendasi cukup relevan (similarity > 0.5).")
    else:
        print("Evaluasi: Rekomendasi kurang relevan (similarity <= 0.5).")



# Contoh pemakaian evaluasi
evaluate_recommendation("The Dark Knight", top_n=5)

"""Melakukan contoh pemakaian fungsi `evaluate_recommendation` dengan film "The Dark Knight" untuk melihat rekomendasi yang dihasilkan dan evaluasi sederhananya."""

# Contoh pemakaian evaluasi
evaluate_recommendation("The Dark Knight", top_n=5)

"""**Hasil Rekomendasi:**

Untuk film "The Dark Knight", sistem merekomendasikan film-film Batman lainnya seperti "The Dark Knight Rises", "Batman Returns", "Batman Begins", "Batman: The Dark Knight Returns, Part 2", dan "Batman Forever". Skor similarity berkisar antara 0.2881 hingga 0.4447. Rata-rata skor similarity adalah 0.3499, yang berdasarkan threshold sederhana (< 0.5) dianggap kurang relevan. Ini menunjukkan bahwa meskipun rekomendasi secara tematik mirip, skor similarity kontennya tidak terlalu tinggi, mungkin karena perbedaan detail dalam overview, cast, atau crew.

## Evaluasi

Mendefinisikan fungsi `calculate_precision_at_n` untuk mengukur performa model content-based filtering menggunakan metrik Precision@N. Fungsi ini mengambil judul film input, matriks similarity, DataFrame data film, jumlah rekomendasi (N), dan ambang batas (threshold) skor similarity untuk menentukan relevansi.

Fungsi ini bekerja dengan:
1. Mencari indeks film input.
2. Mengambil dan mengurutkan skor similarity dengan film lain.
3. Mengidentifikasi film-film dalam N rekomendasi teratas yang memiliki skor similarity di atas ambang batas relevansi.
4. Menghitung Precision@N sebagai rasio jumlah film relevan terhadap N.

Kode ini juga menyertakan contoh penggunaan fungsi `calculate_precision_at_n` untuk film "The Dark Knight" dan "Avatar" dengan ambang batas similarity yang berbeda (0.3 dan 0.5) untuk mendemonstrasikan bagaimana metrik Precision dapat dihitung dan diinterpretasikan dalam konteks ini.
"""

def calculate_precision_at_n(title, similarity_matrix, movie_data, n=5, relevance_threshold=0.3):
    """
    Menghitung Precision@N untuk film tertentu berdasarkan skor cosine similarity.
    Asumsi relevansi film rekomendasi ditentukan dari threshold similarity.

    Args:
        title (str): Judul film input.
        similarity_matrix (np.array): Matriks cosine similarity antar film.
        movie_data (pd.DataFrame): DataFrame dengan kolom 'title'.
        n (int): Jumlah rekomendasi teratas yang dipertimbangkan (N).
        relevance_threshold (float): Ambang batas skor similarity untuk dianggap relevan.

    Returns:
        float: Nilai Precision@N.
        list: Daftar judul film yang dianggap relevan dalam top N rekomendasi.
    """
    title_lower = title.lower()
    if title_lower not in movie_data['title'].str.lower().values:
        print(f"Film '{title}' tidak ditemukan dalam dataset.")
        return 0.0, []

    # Dapatkan indeks film input
    index = movie_data[movie_data['title'].str.lower() == title_lower].index[0]

    # Dapatkan similarity scores untuk film ini, urutkan dari yang tertinggi, kecuali film itu sendiri
    similarities = list(enumerate(similarity_matrix[index]))
    sorted_similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[1:n+1]

    relevant_count = 0
    relevant_movies = []

    for idx, score in sorted_similarities:
        if score >= relevance_threshold:
            relevant_count += 1
            relevant_movies.append(movie_data.iloc[idx]['title'])

    precision = relevant_count / n if n > 0 else 0.0

    return precision, relevant_movies


# Contoh penggunaan
precision_at_5, relevant_recs = calculate_precision_at_n("The Dark Knight", similarity, movie_data, n=5, relevance_threshold=0.3)
print(f"\nPrecision@5 untuk 'The Dark Knight' (threshold=0.3): {precision_at_5:.4f}")
print(f"Film relevan dalam top 5: {relevant_recs}")